## üêæ MatrizDeConfusao do Classificador de Gatos vs Cachorros (com VGG16 e Fine‚ÄëTuning)

Este projeto faz parte do aprendizado e metodo de avalia√ß√£o do Bootcamp promovido pela DIO + e empresa
BairesDev.

1. üßæ Vis√£o geral

Este projeto treina um modelo de CNN usando Transfer Learning sobre a arquitetura VGG16, com fine‚Äëtuning das √∫ltimas camadas, para classificar imagens como gatos ou cachorros. Inclui avalia√ß√£o por matriz de confus√£o, curva ROC e m√©tricas detalhadas (acur√°cia, precis√£o, sensibilidade, especificidade, F1‚Äëscore). Neste projeto foi adicionado ao dataset 1000 imagens de gatos e cachorros diferente da primeira vers√£o em que testei apenas com 100 imagens e n√£o tinha adicionado o c√°lculo da matriz de confus√£o.

2. ‚öôÔ∏è Requisitos

Python 3.8+

Google Colab ou ambiente local com suporte a GPU

Bibliotecas necess√°rias:

TensorFlow ‚â• 2.x

numpy

matplotlib

seaborn

scikit-learn

pandas (opcional, apenas para an√°lise adicional)

pip install tensorflow numpy matplotlib seaborn scikit-learn pandas


3. üöÄ Uso passo a passo

Clone o reposit√≥rio:
git clone https://github.com/HuinaGabriela/MatrizDeConfusaoDoProjetoClassificadorRapidoCNNcomVGG16.git

Entre na pasta do projeto e abra o Colab ou Jupyter Notebook:
cd seu_repositorio && jupyter notebook
ou
colab [notebook.ipynb](https://colab.research.google.com/drive/1-Ah0gGmJ2lUB7qcdyvtgkhgcoVY9Ylvi?authuser=0#scrollTo=8k6j3DqJ5TCu)

4. üìà Resultados esperados

Valida√ß√£o: ~‚ÄØ95% de acur√°cia
Treino/Fine‚Äëtuning: at√© ~‚ÄØ97‚Äë98% de acur√°cia
M√©tricas: precis√£o, sensibilidade e F1‚Äëscore acima de ~‚ÄØ0.90
Curva ROC com AUC alto para ambas as classes (gatos e cachorros)

O modelo tem boa performance fora do treino, mas nas √∫ltimas √©pocas do fine‚Äëtuning,
o val_loss aumentou levemente, sinal de que pode estar memorizando.
Por√©m √© normal quando se usa fine‚Äëtuning com muitos dados.

## üìà Evolu√ß√£o do Treinamento
A seguir, temos o gr√°fico que mostra a evolu√ß√£o da acur√°cia e do erro (loss) ao longo das √©pocas:

![Loss e Acur√°cia](Loss_e_Acur√°cia.PNG)

O gr√°fico indica que o modelo inicialmente teve ganhos r√°pidos de desempenho, com um leve ind√≠cio de overfitting nas √∫ltimas √©pocas, quando a acur√°cia no treino continuou subindo e a do val come√ßou a oscilar.

## üìä Matriz de Confus√£o
A matriz de confus√£o abaixo representa o desempenho do modelo no conjunto de teste, mostrando a quantidade de previs√µes corretas e incorretas para cada classe (Gato e Cachorro):

![Matriz de Confus√£o](Matriz_de_Confus√£o.PNG)

A diagonal principal (de cima √† esquerda e para baixo √† direita) representa os acertos. Valores altos nessa diagonal indicam que o modelo classificou corretamente a maioria das imagens.

# üß† Curva ROC (Receiver Operating Characteristic)

A Curva ROC mostra a capacidade do modelo em distinguir entre gatos e cachorros.
Quanto mais pr√≥ximo da curva esta do canto superior esquerdo, melhor o desempenho.

![Curva ROC](Curva_ROC.PNG)

A √°rea sob a curva (AUC) √© uma m√©trica importante de separabilidade. Um AUC pr√≥ximo de 1.0 indica que o modelo tem uma excelente capacidade de discriminar entre as classes.

5. üß† Interpreta√ß√£o das m√©tricas
Acur√°cia: percentual de imagens classificadas corretamente.
Precis√£o: das imagens que previu como "gato", quantas eram realmente gatos.
Sensibilidade (Recall): das imagens que eram de gatos, quantas foram identificadas.
Especificidade: das imagens que n√£o eram gatos (cachorros), quantas o modelo reconheceu corretamente.
F1‚Äëscore: m√©dia harm√¥nica entre precis√£o e sensibilidade.

üìä O que √© a Matriz de Confus√£o?
A matriz de confus√£o √© uma ferramenta usada para entender como o modelo est√° acertando e errando suas previs√µes. No caso de duas classes (gatos e cachorros), ela tem este formato:

 |                        | **Previsto: Gato**      | **Previsto: Cachorro** |
|------------------------|--------------------------|--------------------------|
| **Verdadeiro: Gato**   | VP (Verdadeiro Positivo) | FN (Falso Negativo)     |
| **Verdadeiro: Cachorro** | FP (Falso Positivo)     | VN (Verdadeiro Negativo)|


- **VP (True Positive)**: modelo disse "gato" e era "gato".
- **VN (True Negative)**: modelo disse "cachorro" e era "cachorro".
- **FP (False Positive)**: modelo disse "gato", mas era "cachorro".
- **FN (False Negative)**: modelo disse "cachorro", mas era "gato".

A partir desses valores, calculamos:

| **M√©trica**     | **F√≥rmula**                                  | **Interpreta√ß√£o**                                                                 |
|------------------|----------------------------------------------|------------------------------------------------------------------------------------|
| Acur√°cia         | (VP + VN) / Total                            | Propor√ß√£o total de acertos do modelo                                              |
| Precis√£o         | VP / (VP + FP)                               | Das vezes que o modelo disse ‚Äúgato‚Äù, quantas vezes ele estava certo?             |
| Recall (Sens.)   | VP / (VP + FN)                               | Das imagens que realmente eram ‚Äúgato‚Äù, quantas o modelo identificou corretamente? |
| Especificidade   | VN / (VN + FP)                               | Das imagens que eram ‚Äúcachorro‚Äù, quantas o modelo classificou corretamente?       |
| F1‚ÄëScore         | 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall) | Combina√ß√£o entre precis√£o e recall ‚Äî √∫til com classes desbalanceadas              |





